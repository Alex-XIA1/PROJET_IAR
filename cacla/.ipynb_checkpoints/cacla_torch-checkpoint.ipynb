{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# Installs the necessary Python and system libraries\n",
    "try:\n",
    "    from easypip import easyimport, easyinstall, is_notebook\n",
    "except ModuleNotFoundError as e:\n",
    "    get_ipython().run_line_magic(\"pip\", \"install easypip\")\n",
    "    from easypip import easyimport, easyinstall, is_notebook\n",
    "\n",
    "easyinstall(\"bbrl>=0.2.2\")\n",
    "easyinstall(\"swig\")\n",
    "easyinstall(\"bbrl_gymnasium>=0.2.0\")\n",
    "easyinstall(\"bbrl_gymnasium[box2d]\")\n",
    "easyinstall(\"bbrl_gymnasium[classic_control]\")\n",
    "easyinstall(\"tensorboard\")\n",
    "easyinstall(\"moviepy\")\n",
    "easyinstall(\"box2d-kengz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import math\n",
    "import time\n",
    "\n",
    "from moviepy.editor import ipython_display as video_display\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, Optional\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import bbrl_gymnasium\n",
    "\n",
    "import copy\n",
    "from abc import abstractmethod, ABC\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2024-01-11 09:18:42 GMT\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import gymnasium\n",
    "from gymnasium import logger as gymlogger\n",
    "# from gym.wrappers import Monitor # deprecated 2023 - https://stackoverflow.com/questions/71520568/importerror-cannot-import-name-monitor-from-gym-wrappers\n",
    "from gymnasium.wrappers.record_video import RecordVideo\n",
    "gymlogger.set_level(40) #error only\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"\\n\",date.today(), datetime.now().strftime(\"%H:%M:%S\"),\"GMT\") # timestamp is greenwich time\n",
    "print(\"OK.\")\n",
    "\n",
    "def show_video(loop=True, num=0):\n",
    "    mp4list = glob.glob(f'videoTest/rl-video-episode-{num}.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        if loop == True:\n",
    "            ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:videoTest/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(encoded.decode('ascii'))))\n",
    "        else:\n",
    "            ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                    controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:videoTest/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, './videoTest',  episode_trigger = lambda episode_number: True) # !!! 2023\n",
    "    env.reset() # !!! 2023\n",
    "    #env = Monitor(env, './video', force=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Continuous action version of the classic cart-pole system implemented by Rich\n",
    "Sutton et al.\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gymnasium.envs.classic_control.cartpole import CartPoleEnv\n",
    "from gymnasium import logger, spaces\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "import sys\n",
    "sys.modules[__name__]\n",
    "\n",
    "class ContinuousEnvArticle(CartPoleEnv):\n",
    "    \"\"\"Continuous version  of the CartPole-v1 environment\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.min_action = -1.0\n",
    "        self.max_action = 1.0\n",
    "        self.action_space = spaces.Box(\n",
    "            self.min_action, self.max_action, shape=(1,), dtype=np.float64\n",
    "        )\n",
    "        self.tau = 0.1\n",
    "        \n",
    "        self.x_threshold = 1\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array(\n",
    "            [\n",
    "                self.x_threshold * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "                self.theta_threshold_radians * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        if action > self.max_action:\n",
    "            action = np.array(self.max_action)\n",
    "        elif action < self.min_action:\n",
    "            action = np.array(self.min_action)\n",
    "        assert self.state is not None, \"Call reset before using step method.\"\n",
    "\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = self.force_mag * float(action)\n",
    "\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        temp = (\n",
    "            force + self.polemass_length * theta_dot**2 * sintheta\n",
    "        ) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (\n",
    "            self.length * (4.0 / 3.0 - self.masspole * costheta**2 / self.total_mass)\n",
    "        )\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        if self.kinematics_integrator == \"euler\":\n",
    "            x = x + self.tau * x_dot\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "        else:  # semi-implicit euler\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            x = x + self.tau * x_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        terminated = bool(\n",
    "            x < -self.x_threshold\n",
    "            or x > self.x_threshold\n",
    "            or theta < -self.theta_threshold_radians\n",
    "            or theta > self.theta_threshold_radians\n",
    "        )\n",
    "\n",
    "        if not terminated:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_terminated is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_terminated = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_terminated == 0:\n",
    "                logger.warn(\n",
    "                    \"You are calling 'step()' even though this \"\n",
    "                    \"environment has already returned terminated = True. You \"\n",
    "                    \"should always call 'reset()' once you receive 'terminated = \"\n",
    "                    \"True' -- any further steps are undefined behavior.\"\n",
    "                )\n",
    "            self.steps_beyond_terminated += 1\n",
    "            reward = 0\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), reward, terminated, False, {}\n",
    "    \n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        # Note that if you use custom reset bounds, it may lead to out-of-bound\n",
    "        # state/observations.\n",
    "        x = self.np_random.uniform(low=-0.05, high=0.05, size=(1,))\n",
    "        self.state = 0, 0, x, 0\n",
    "        self.steps_beyond_terminated = None\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), {}\n",
    "\"\"\"\n",
    "Continuous action version of the classic cart-pole system implemented by Rich\n",
    "Sutton et al.\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gymnasium.envs.classic_control.cartpole import CartPoleEnv\n",
    "from gymnasium import logger, spaces\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "import sys\n",
    "sys.modules[__name__]\n",
    "\n",
    "class ContinuousEnvCACLA(CartPoleEnv):\n",
    "    \"\"\"Continuous version  of the CartPole-v1 environment\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.min_action = -1.0\n",
    "        self.max_action = 1.0\n",
    "        self.action_space = spaces.Box(\n",
    "            self.min_action, self.max_action, shape=(1,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        if action > self.max_action:\n",
    "            action = np.array(self.max_action)\n",
    "        elif action < self.min_action:\n",
    "            action = np.array(self.min_action)\n",
    "        assert self.state is not None, \"Call reset before using step method.\"\n",
    "\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = self.force_mag * float(action)\n",
    "\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        temp = (\n",
    "            force + self.polemass_length * theta_dot**2 * sintheta\n",
    "        ) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (\n",
    "            self.length * (4.0 / 3.0 - self.masspole * costheta**2 / self.total_mass)\n",
    "        )\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        if self.kinematics_integrator == \"euler\":\n",
    "            x = x + self.tau * x_dot\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "        else:  # semi-implicit euler\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            x = x + self.tau * x_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        terminated = bool(\n",
    "            x < -self.x_threshold\n",
    "            or x > self.x_threshold\n",
    "            or theta < -self.theta_threshold_radians\n",
    "            or theta > self.theta_threshold_radians\n",
    "        )\n",
    "\n",
    "        if not terminated:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_terminated is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_terminated = 0\n",
    "            reward = -1\n",
    "        else:\n",
    "            if self.steps_beyond_terminated == 0:\n",
    "                logger.warn(\n",
    "                    \"You are calling 'step()' even though this \"\n",
    "                    \"environment has already returned terminated = True. You \"\n",
    "                    \"should always call 'reset()' once you receive 'terminated = \"\n",
    "                    \"True' -- any further steps are undefined behavior.\"\n",
    "                )\n",
    "            self.steps_beyond_terminated += 1\n",
    "            reward = 0\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), reward, terminated, False, {}\n",
    "\n",
    "try:\n",
    "  gymnasium.envs.register(\n",
    "      id='CartpoleEnvCacla',\n",
    "      entry_point='__main__:ContinuousEnvCACLA',\n",
    "      max_episode_steps=500\n",
    "  )\n",
    "except:\n",
    "    print(\"Except\")\n",
    "    pass\n",
    "try:\n",
    "  gymnasium.envs.register(\n",
    "      id='CartpoleEnvArticle',\n",
    "      entry_point='__main__:ContinuousEnvArticle',\n",
    "      max_episode_steps=500\n",
    "  )\n",
    "except:\n",
    "    print(\"Except\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn.functional import mse_loss\n",
    "class Cacla(nn.Module):\n",
    "    def __init__(self, in_dim, \n",
    "                 h_dim, activation=nn.Tanh,\n",
    "                 discount_factor=0.95, \n",
    "                 gaussian_noise=0.01, \n",
    "                 var=False, \n",
    "                 exploration='gaussian'):\n",
    "        super(Cacla,self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(in_dim, h_dim),\n",
    "            activation(),\n",
    "            nn.Linear(h_dim, 1),\n",
    "            #activation()\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(in_dim, h_dim),\n",
    "            activation(),\n",
    "            nn.Linear(h_dim, 1),\n",
    "        )\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.gaussian_noise = gaussian_noise\n",
    "        self.vart = 1\n",
    "        self.beta = 0.001\n",
    "        self.with_var = var\n",
    "\n",
    "        self.eps = 1\n",
    "        self.eps_decay = 0.99\n",
    "        self.eps_min = 0.01\n",
    "        \n",
    "        self.exploration = 'gaussian'\n",
    "    \n",
    "    def forward(self, x, testing=False):\n",
    "        x = torch.from_numpy(x).unsqueeze(0)\n",
    "        if testing: return (None, self.actor(x)) \n",
    "        return self.critic(x), self.actor(x)\n",
    "    \n",
    "    # Loss computation\n",
    "    def compute_critic_loss(self, value, target):\n",
    "        delta = (target - value).detach()\n",
    "        loss =  mse_loss(value, target)\n",
    "        n_update = 1\n",
    "        if self.with_var and delta > 0:\n",
    "            n_update = torch.ceil(delta/np.sqrt(self.vart)).item()\n",
    "            self.vart = (1-self.beta)*self.vart +self.beta*loss.detach()\n",
    "        return loss, int(n_update)\n",
    "    \n",
    "    def compute_actor_loss(self, value, target):\n",
    "        return mse_loss(value, target)\n",
    "    \n",
    "    # Exploration\n",
    "    def sample(self, x):\n",
    "        if self.exploration == 'gaussian':\n",
    "            return self.sample_gaussian(x)\n",
    "        elif self.exploration == 'epsilon':\n",
    "            return self.sample_epsilon(x)\n",
    "        else: \n",
    "            print('Exploration unknown: ', self.exploration)       \n",
    "    \n",
    "    def sample_gaussian(self, x):\n",
    "        return (x + np.random.normal(0,self.gaussian_noise))\n",
    "    \n",
    "    def sample_epsilon(self, x, inf=-1, sup=1):\n",
    "        if torch.rand(1) > self.eps: return x\n",
    "        else: return np.random.rand() * (sup - inf) - inf\n",
    "\n",
    "\n",
    "def test(eval_env, model, n_test = 10, noise_std = 0.3):\n",
    "    cum_reward = 0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_test):\n",
    "            done = False\n",
    "            truncated = False\n",
    "            obs0,_ = eval_env.reset()\n",
    "            while not done and not truncated:\n",
    "                _, a0 = model(obs0, testing=True)  \n",
    "                obs0, reward, done,truncated,_ = eval_env.step(a0) \n",
    "                cum_reward += reward\n",
    "    return cum_reward/n_test\n",
    "\n",
    "def addnoise(x, std):\n",
    "    return x + np.random.normal(0,std)\n",
    "    \n",
    "def train(eval_env, \n",
    "          train_env,\n",
    "          model,\n",
    "          optim, \n",
    "          eval_interval=1000, \n",
    "          step_max=100000, \n",
    "          n_test=10, \n",
    "          noise_std=0.3):\n",
    "    obs ,_ = train_env.reset()\n",
    "    scores = []\n",
    "    optim_critic, optim_actor = optim\n",
    "    # boucle d'apprentissage\n",
    "    for it in range(step_max):\n",
    "        v0, a0 = model(obs)\n",
    "        obs0 = obs\n",
    "        action = model.sample(a0).detach()\n",
    "        obs, reward, done, truncated,reste = train_env.step(addnoise(action, noise_std)) \n",
    "        \n",
    "        # Compute losses\n",
    "        with torch.no_grad(): v1, _ = model(obs)\n",
    "        target_v = addnoise(reward, noise_std) + model.discount_factor*v1\n",
    "        optim_critic.zero_grad()\n",
    "        critic_loss, n_update = model.compute_critic_loss(v0, target=target_v)\n",
    "        critic_loss.backward()\n",
    "        optim_critic.step()\n",
    "        if target_v - v0 > 0: \n",
    "            for _ in range(n_update):\n",
    "                optim_actor.zero_grad()\n",
    "                mse_loss(model(obs0)[1], action).backward()\n",
    "                optim_actor.step()\n",
    "        if done or truncated: obs,_ = train_env.reset()\n",
    "        if it % eval_interval == 0:\n",
    "            perf = test(eval_env, model, n_test, noise_std)\n",
    "            scores.append((it, perf))\n",
    "            print(f'{it = } | reward {perf}')\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= run = 1 / 18 =========\n",
      "it = 0 | reward 30.8\n",
      "it = 1024 | reward 35.6\n",
      "it = 2048 | reward 39.6\n",
      "it = 3072 | reward 38.4\n",
      "it = 4096 | reward 39.6\n",
      "it = 5120 | reward 36.9\n",
      "it = 6144 | reward 74.2\n",
      "it = 7168 | reward 50.1\n",
      "it = 8192 | reward 42.5\n",
      "it = 9216 | reward 95.2\n",
      "it = 10240 | reward 235.4\n",
      "it = 11264 | reward 103.2\n",
      "it = 12288 | reward 232.5\n",
      "it = 13312 | reward 68.5\n",
      "it = 14336 | reward 143.9\n",
      "it = 15360 | reward 99.5\n",
      "it = 16384 | reward 145.2\n",
      "it = 17408 | reward 193.7\n",
      "it = 18432 | reward 111.4\n",
      "it = 19456 | reward 116.6\n",
      "it = 20480 | reward 229.6\n",
      "it = 21504 | reward 131.6\n",
      "it = 22528 | reward 201.6\n",
      "it = 23552 | reward 291.2\n",
      "it = 24576 | reward 193.0\n",
      "it = 25600 | reward 110.1\n",
      "it = 26624 | reward 234.5\n",
      "it = 27648 | reward 464.3\n",
      "it = 28672 | reward 346.4\n",
      "it = 29696 | reward 486.3\n",
      "it = 30720 | reward 223.5\n",
      "it = 31744 | reward 340.5\n",
      "it = 32768 | reward 418.4\n",
      "it = 33792 | reward 299.8\n",
      "it = 34816 | reward 183.0\n",
      "it = 35840 | reward 310.1\n",
      "it = 36864 | reward 214.4\n",
      "it = 37888 | reward 269.5\n",
      "it = 38912 | reward 220.1\n",
      "it = 39936 | reward 146.0\n",
      "it = 40960 | reward 56.6\n",
      "it = 41984 | reward 65.2\n",
      "it = 43008 | reward 118.0\n",
      "it = 44032 | reward 166.7\n",
      "it = 45056 | reward 165.2\n",
      "it = 46080 | reward 151.4\n",
      "it = 47104 | reward 125.6\n",
      "it = 48128 | reward 69.2\n",
      "it = 49152 | reward 50.8\n",
      "it = 50176 | reward 24.6\n",
      "it = 51200 | reward 40.1\n",
      "it = 52224 | reward 188.0\n",
      "it = 53248 | reward 83.4\n",
      "it = 54272 | reward 218.0\n",
      "it = 55296 | reward 147.1\n",
      "it = 56320 | reward 101.0\n",
      "it = 57344 | reward 142.9\n",
      "it = 58368 | reward 69.0\n",
      "it = 59392 | reward 193.6\n",
      "it = 60416 | reward 127.5\n",
      "it = 61440 | reward 231.9\n",
      "it = 62464 | reward 213.8\n",
      "it = 63488 | reward 270.3\n",
      "it = 64512 | reward 247.1\n",
      "it = 65536 | reward 244.0\n",
      "it = 66560 | reward 100.0\n",
      "it = 67584 | reward 108.6\n",
      "it = 68608 | reward 167.3\n",
      "it = 69632 | reward 248.6\n",
      "it = 70656 | reward 315.7\n",
      "it = 71680 | reward 376.5\n",
      "it = 72704 | reward 256.8\n",
      "it = 73728 | reward 298.7\n",
      "it = 74752 | reward 428.5\n",
      "it = 75776 | reward 500.0\n",
      "it = 76800 | reward 434.8\n",
      "it = 77824 | reward 332.0\n",
      "it = 78848 | reward 495.6\n",
      "it = 79872 | reward 500.0\n",
      "it = 80896 | reward 500.0\n",
      "it = 81920 | reward 238.9\n",
      "it = 82944 | reward 298.0\n",
      "it = 83968 | reward 250.4\n",
      "it = 84992 | reward 230.6\n",
      "it = 86016 | reward 473.5\n",
      "it = 87040 | reward 347.1\n",
      "it = 88064 | reward 257.1\n",
      "it = 89088 | reward 467.2\n",
      "it = 90112 | reward 172.8\n",
      "it = 91136 | reward 201.9\n",
      "it = 92160 | reward 241.1\n",
      "it = 93184 | reward 492.3\n",
      "it = 94208 | reward 498.4\n",
      "it = 95232 | reward 232.8\n",
      "it = 96256 | reward 433.6\n",
      "it = 97280 | reward 485.3\n",
      "it = 98304 | reward 211.0\n",
      "it = 99328 | reward 244.4\n",
      "it = 100352 | reward 337.6\n",
      "it = 101376 | reward 177.1\n",
      "======= run = 2 / 18 =========\n",
      "it = 0 | reward 15.9\n",
      "it = 1024 | reward 14.9\n",
      "it = 2048 | reward 20.8\n",
      "it = 3072 | reward 43.9\n",
      "it = 4096 | reward 62.3\n",
      "it = 5120 | reward 50.6\n",
      "it = 6144 | reward 53.1\n",
      "it = 7168 | reward 53.8\n",
      "it = 8192 | reward 53.2\n",
      "it = 9216 | reward 62.0\n",
      "it = 10240 | reward 57.9\n",
      "it = 11264 | reward 41.0\n",
      "it = 12288 | reward 90.4\n",
      "it = 13312 | reward 97.8\n",
      "it = 14336 | reward 115.0\n",
      "it = 15360 | reward 110.3\n",
      "it = 16384 | reward 52.3\n",
      "it = 17408 | reward 70.5\n",
      "it = 18432 | reward 60.6\n",
      "it = 19456 | reward 87.5\n",
      "it = 20480 | reward 37.9\n",
      "it = 21504 | reward 71.1\n",
      "it = 22528 | reward 87.3\n",
      "it = 23552 | reward 105.0\n",
      "it = 24576 | reward 79.2\n",
      "it = 25600 | reward 106.9\n",
      "it = 26624 | reward 153.9\n",
      "it = 27648 | reward 136.5\n",
      "it = 28672 | reward 94.4\n",
      "it = 29696 | reward 110.4\n",
      "it = 30720 | reward 80.5\n",
      "it = 31744 | reward 96.7\n",
      "it = 32768 | reward 69.7\n",
      "it = 33792 | reward 84.7\n",
      "it = 34816 | reward 70.3\n",
      "it = 35840 | reward 54.6\n",
      "it = 36864 | reward 98.2\n",
      "it = 37888 | reward 167.1\n",
      "it = 38912 | reward 125.8\n",
      "it = 39936 | reward 148.1\n",
      "it = 40960 | reward 125.8\n",
      "it = 41984 | reward 130.0\n",
      "it = 43008 | reward 258.7\n",
      "it = 44032 | reward 129.1\n",
      "it = 45056 | reward 135.6\n",
      "it = 46080 | reward 258.4\n",
      "it = 47104 | reward 111.0\n",
      "it = 48128 | reward 131.5\n",
      "it = 49152 | reward 86.5\n",
      "it = 50176 | reward 229.2\n",
      "it = 51200 | reward 154.1\n",
      "it = 52224 | reward 188.7\n",
      "it = 53248 | reward 169.5\n",
      "it = 54272 | reward 105.7\n",
      "it = 55296 | reward 144.9\n",
      "it = 56320 | reward 112.3\n",
      "it = 57344 | reward 143.2\n",
      "it = 58368 | reward 254.4\n",
      "it = 59392 | reward 211.0\n",
      "it = 60416 | reward 215.6\n",
      "it = 61440 | reward 255.3\n",
      "it = 62464 | reward 171.1\n",
      "it = 63488 | reward 230.5\n",
      "it = 64512 | reward 278.1\n",
      "it = 65536 | reward 318.3\n",
      "it = 66560 | reward 328.8\n",
      "it = 67584 | reward 436.8\n",
      "it = 68608 | reward 395.3\n",
      "it = 69632 | reward 106.8\n",
      "it = 70656 | reward 111.8\n",
      "it = 71680 | reward 165.9\n",
      "it = 72704 | reward 111.9\n",
      "it = 73728 | reward 82.8\n",
      "it = 74752 | reward 315.8\n",
      "it = 75776 | reward 297.3\n",
      "it = 76800 | reward 428.8\n",
      "it = 77824 | reward 181.4\n",
      "it = 78848 | reward 179.3\n",
      "it = 79872 | reward 130.3\n",
      "it = 80896 | reward 175.5\n",
      "it = 81920 | reward 270.0\n",
      "it = 82944 | reward 156.1\n",
      "it = 83968 | reward 182.3\n",
      "it = 84992 | reward 313.1\n",
      "it = 86016 | reward 311.6\n",
      "it = 87040 | reward 281.5\n",
      "it = 88064 | reward 333.9\n",
      "it = 89088 | reward 171.4\n",
      "it = 90112 | reward 130.5\n",
      "it = 91136 | reward 170.3\n",
      "it = 92160 | reward 211.3\n",
      "it = 93184 | reward 224.4\n",
      "it = 94208 | reward 248.9\n",
      "it = 95232 | reward 450.3\n",
      "it = 96256 | reward 225.3\n",
      "it = 97280 | reward 156.3\n",
      "it = 98304 | reward 70.9\n",
      "it = 99328 | reward 204.8\n",
      "it = 100352 | reward 162.8\n",
      "it = 101376 | reward 191.1\n",
      "======= run = 3 / 18 =========\n",
      "it = 0 | reward 16.5\n",
      "it = 1024 | reward 15.6\n",
      "it = 2048 | reward 32.5\n",
      "it = 3072 | reward 29.0\n",
      "it = 4096 | reward 29.6\n",
      "it = 5120 | reward 47.3\n",
      "it = 6144 | reward 51.6\n",
      "it = 7168 | reward 52.0\n",
      "it = 8192 | reward 41.7\n",
      "it = 9216 | reward 72.1\n",
      "it = 10240 | reward 105.6\n",
      "it = 11264 | reward 82.1\n",
      "it = 12288 | reward 82.6\n",
      "it = 13312 | reward 54.0\n",
      "it = 14336 | reward 104.8\n",
      "it = 15360 | reward 80.9\n",
      "it = 16384 | reward 131.6\n",
      "it = 17408 | reward 118.0\n",
      "it = 18432 | reward 128.4\n",
      "it = 19456 | reward 146.0\n",
      "it = 20480 | reward 157.5\n",
      "it = 21504 | reward 155.3\n",
      "it = 22528 | reward 126.3\n",
      "it = 23552 | reward 201.2\n",
      "it = 24576 | reward 164.0\n",
      "it = 25600 | reward 468.9\n",
      "it = 26624 | reward 105.7\n",
      "it = 27648 | reward 192.3\n",
      "it = 28672 | reward 234.0\n",
      "it = 29696 | reward 163.2\n",
      "it = 30720 | reward 259.2\n",
      "it = 31744 | reward 277.9\n",
      "it = 32768 | reward 110.9\n",
      "it = 33792 | reward 124.1\n",
      "it = 34816 | reward 43.1\n",
      "it = 35840 | reward 369.2\n",
      "it = 36864 | reward 446.2\n",
      "it = 37888 | reward 322.9\n",
      "it = 38912 | reward 78.4\n",
      "it = 39936 | reward 112.1\n",
      "it = 40960 | reward 221.6\n",
      "it = 41984 | reward 366.0\n",
      "it = 43008 | reward 299.4\n",
      "it = 44032 | reward 230.2\n",
      "it = 45056 | reward 110.1\n",
      "it = 46080 | reward 117.0\n",
      "it = 47104 | reward 44.8\n",
      "it = 48128 | reward 103.6\n",
      "it = 49152 | reward 116.9\n",
      "it = 50176 | reward 107.0\n",
      "it = 51200 | reward 118.3\n",
      "it = 52224 | reward 109.2\n",
      "it = 53248 | reward 170.2\n",
      "it = 54272 | reward 203.2\n",
      "it = 55296 | reward 121.5\n",
      "it = 56320 | reward 100.3\n",
      "it = 57344 | reward 65.3\n",
      "it = 58368 | reward 177.8\n",
      "it = 59392 | reward 133.6\n",
      "it = 60416 | reward 203.5\n",
      "it = 61440 | reward 363.7\n",
      "it = 62464 | reward 271.4\n",
      "it = 63488 | reward 131.3\n",
      "it = 64512 | reward 91.1\n",
      "it = 65536 | reward 43.1\n",
      "it = 66560 | reward 147.6\n",
      "it = 67584 | reward 152.3\n",
      "it = 68608 | reward 127.7\n",
      "it = 69632 | reward 50.0\n",
      "it = 70656 | reward 131.7\n",
      "it = 71680 | reward 87.2\n",
      "it = 72704 | reward 90.9\n",
      "it = 73728 | reward 90.4\n",
      "it = 74752 | reward 134.2\n",
      "it = 75776 | reward 211.2\n",
      "it = 76800 | reward 191.0\n",
      "it = 77824 | reward 341.5\n",
      "it = 78848 | reward 209.4\n",
      "it = 79872 | reward 229.2\n",
      "it = 80896 | reward 500.0\n",
      "it = 81920 | reward 138.6\n",
      "it = 82944 | reward 199.3\n",
      "it = 83968 | reward 258.5\n",
      "it = 84992 | reward 130.1\n",
      "it = 86016 | reward 160.3\n",
      "it = 87040 | reward 272.5\n",
      "it = 88064 | reward 477.2\n",
      "it = 89088 | reward 422.2\n",
      "it = 90112 | reward 226.9\n",
      "it = 91136 | reward 337.2\n",
      "it = 92160 | reward 289.4\n",
      "it = 93184 | reward 323.0\n",
      "it = 94208 | reward 117.0\n",
      "it = 95232 | reward 337.1\n",
      "it = 96256 | reward 279.6\n",
      "it = 97280 | reward 334.9\n",
      "it = 98304 | reward 167.6\n",
      "it = 99328 | reward 342.1\n",
      "it = 100352 | reward 210.0\n",
      "it = 101376 | reward 176.3\n",
      "======= run = 4 / 18 =========\n",
      "it = 0 | reward 18.2\n",
      "it = 1024 | reward 21.2\n",
      "it = 2048 | reward 67.3\n",
      "it = 3072 | reward 26.4\n",
      "it = 4096 | reward 59.7\n",
      "it = 5120 | reward 87.4\n",
      "it = 6144 | reward 35.7\n",
      "it = 7168 | reward 66.6\n",
      "it = 8192 | reward 71.1\n",
      "it = 9216 | reward 80.0\n",
      "it = 10240 | reward 47.3\n",
      "it = 11264 | reward 53.2\n",
      "it = 12288 | reward 146.7\n",
      "it = 13312 | reward 143.1\n",
      "it = 14336 | reward 138.7\n",
      "it = 15360 | reward 131.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it = 16384 | reward 100.9\n",
      "it = 17408 | reward 109.3\n",
      "it = 18432 | reward 117.6\n",
      "it = 19456 | reward 98.7\n",
      "it = 20480 | reward 219.2\n",
      "it = 21504 | reward 255.7\n",
      "it = 22528 | reward 132.5\n",
      "it = 23552 | reward 76.6\n",
      "it = 24576 | reward 149.3\n",
      "it = 25600 | reward 101.6\n",
      "it = 26624 | reward 164.8\n",
      "it = 27648 | reward 182.0\n",
      "it = 28672 | reward 348.4\n",
      "it = 29696 | reward 120.3\n",
      "it = 30720 | reward 210.5\n",
      "it = 31744 | reward 182.7\n",
      "it = 32768 | reward 231.1\n",
      "it = 33792 | reward 183.4\n",
      "it = 34816 | reward 297.8\n",
      "it = 35840 | reward 200.5\n",
      "it = 36864 | reward 125.8\n",
      "it = 37888 | reward 129.2\n",
      "it = 38912 | reward 118.2\n",
      "it = 39936 | reward 136.0\n",
      "it = 40960 | reward 41.1\n",
      "it = 41984 | reward 156.1\n",
      "it = 43008 | reward 332.5\n",
      "it = 44032 | reward 220.3\n",
      "it = 45056 | reward 157.5\n",
      "it = 46080 | reward 57.4\n",
      "it = 47104 | reward 103.3\n",
      "it = 48128 | reward 113.6\n",
      "it = 49152 | reward 58.1\n",
      "it = 50176 | reward 132.8\n",
      "it = 51200 | reward 42.1\n",
      "it = 52224 | reward 118.0\n",
      "it = 53248 | reward 148.7\n",
      "it = 54272 | reward 132.1\n",
      "it = 55296 | reward 88.6\n",
      "it = 56320 | reward 111.9\n",
      "it = 57344 | reward 154.1\n",
      "it = 58368 | reward 482.5\n",
      "it = 59392 | reward 237.0\n",
      "it = 60416 | reward 158.2\n",
      "it = 61440 | reward 195.7\n",
      "it = 62464 | reward 228.8\n",
      "it = 63488 | reward 295.0\n",
      "it = 64512 | reward 158.5\n",
      "it = 65536 | reward 115.5\n",
      "it = 66560 | reward 236.1\n",
      "it = 67584 | reward 116.5\n",
      "it = 68608 | reward 137.4\n",
      "it = 69632 | reward 128.2\n",
      "it = 70656 | reward 227.1\n",
      "it = 71680 | reward 188.9\n",
      "it = 72704 | reward 124.8\n",
      "it = 73728 | reward 171.3\n",
      "it = 74752 | reward 144.8\n",
      "it = 75776 | reward 99.3\n",
      "it = 76800 | reward 159.6\n",
      "it = 77824 | reward 162.8\n",
      "it = 78848 | reward 197.2\n",
      "it = 79872 | reward 240.6\n",
      "it = 80896 | reward 128.7\n",
      "it = 81920 | reward 266.3\n",
      "it = 82944 | reward 137.8\n",
      "it = 83968 | reward 157.1\n",
      "it = 84992 | reward 424.9\n",
      "it = 86016 | reward 271.8\n",
      "it = 87040 | reward 441.1\n",
      "it = 88064 | reward 321.7\n",
      "it = 89088 | reward 234.0\n",
      "it = 90112 | reward 282.2\n",
      "it = 91136 | reward 121.9\n",
      "it = 92160 | reward 111.8\n",
      "it = 93184 | reward 32.3\n",
      "it = 94208 | reward 308.9\n",
      "it = 95232 | reward 331.6\n",
      "it = 96256 | reward 132.4\n",
      "it = 97280 | reward 126.8\n",
      "it = 98304 | reward 125.6\n",
      "it = 99328 | reward 86.3\n",
      "it = 100352 | reward 105.2\n",
      "it = 101376 | reward 180.5\n",
      "======= run = 5 / 18 =========\n",
      "it = 0 | reward 9.7\n",
      "it = 1024 | reward 13.1\n",
      "it = 2048 | reward 28.4\n",
      "it = 3072 | reward 37.8\n",
      "it = 4096 | reward 37.3\n",
      "it = 5120 | reward 58.6\n",
      "it = 6144 | reward 33.5\n",
      "it = 7168 | reward 52.7\n",
      "it = 8192 | reward 67.1\n",
      "it = 9216 | reward 56.3\n",
      "it = 10240 | reward 53.9\n",
      "it = 11264 | reward 71.5\n",
      "it = 12288 | reward 40.4\n",
      "it = 13312 | reward 87.4\n",
      "it = 14336 | reward 59.4\n",
      "it = 15360 | reward 76.7\n",
      "it = 16384 | reward 111.4\n",
      "it = 17408 | reward 135.9\n",
      "it = 18432 | reward 139.9\n",
      "it = 19456 | reward 129.0\n",
      "it = 20480 | reward 113.7\n",
      "it = 21504 | reward 119.5\n",
      "it = 22528 | reward 69.0\n",
      "it = 23552 | reward 75.7\n",
      "it = 24576 | reward 118.4\n",
      "it = 25600 | reward 108.8\n",
      "it = 26624 | reward 221.1\n",
      "it = 27648 | reward 179.0\n",
      "it = 28672 | reward 164.2\n",
      "it = 29696 | reward 172.6\n",
      "it = 30720 | reward 231.4\n",
      "it = 31744 | reward 131.8\n",
      "it = 32768 | reward 50.8\n",
      "it = 33792 | reward 323.7\n",
      "it = 34816 | reward 303.9\n",
      "it = 35840 | reward 142.9\n",
      "it = 36864 | reward 116.3\n",
      "it = 37888 | reward 176.8\n",
      "it = 38912 | reward 359.3\n",
      "it = 39936 | reward 292.3\n",
      "it = 40960 | reward 236.2\n",
      "it = 41984 | reward 142.1\n",
      "it = 43008 | reward 178.4\n",
      "it = 44032 | reward 137.8\n",
      "it = 45056 | reward 221.6\n",
      "it = 46080 | reward 328.6\n",
      "it = 47104 | reward 175.9\n",
      "it = 48128 | reward 295.7\n",
      "it = 49152 | reward 173.9\n",
      "it = 50176 | reward 297.8\n",
      "it = 51200 | reward 169.5\n",
      "it = 52224 | reward 108.6\n",
      "it = 53248 | reward 486.2\n",
      "it = 54272 | reward 172.3\n",
      "it = 55296 | reward 81.0\n",
      "it = 56320 | reward 143.9\n",
      "it = 57344 | reward 129.6\n",
      "it = 58368 | reward 145.7\n",
      "it = 59392 | reward 155.6\n",
      "it = 60416 | reward 172.8\n",
      "it = 61440 | reward 270.9\n",
      "it = 62464 | reward 158.8\n",
      "it = 63488 | reward 240.7\n",
      "it = 64512 | reward 160.7\n",
      "it = 65536 | reward 125.3\n",
      "it = 66560 | reward 111.7\n",
      "it = 67584 | reward 83.3\n",
      "it = 68608 | reward 159.0\n",
      "it = 69632 | reward 63.0\n",
      "it = 70656 | reward 67.4\n",
      "it = 71680 | reward 66.1\n",
      "it = 72704 | reward 27.6\n",
      "it = 73728 | reward 81.8\n",
      "it = 74752 | reward 92.9\n",
      "it = 75776 | reward 118.7\n",
      "it = 76800 | reward 187.8\n",
      "it = 77824 | reward 199.8\n",
      "it = 78848 | reward 179.7\n",
      "it = 79872 | reward 192.2\n",
      "it = 80896 | reward 193.9\n",
      "it = 81920 | reward 193.9\n",
      "it = 82944 | reward 160.5\n",
      "it = 83968 | reward 137.2\n",
      "it = 84992 | reward 272.6\n",
      "it = 86016 | reward 500.0\n",
      "it = 87040 | reward 500.0\n",
      "it = 88064 | reward 306.9\n",
      "it = 89088 | reward 161.4\n",
      "it = 90112 | reward 106.1\n",
      "it = 91136 | reward 64.5\n",
      "it = 92160 | reward 440.2\n",
      "it = 93184 | reward 297.3\n",
      "it = 94208 | reward 396.6\n",
      "it = 95232 | reward 197.7\n",
      "it = 96256 | reward 247.3\n",
      "it = 97280 | reward 185.4\n",
      "it = 98304 | reward 124.5\n",
      "it = 99328 | reward 173.1\n",
      "it = 100352 | reward 394.4\n",
      "it = 101376 | reward 243.8\n",
      "======= run = 6 / 18 =========\n",
      "it = 0 | reward 12.1\n",
      "it = 1024 | reward 12.7\n",
      "it = 2048 | reward 35.9\n",
      "it = 3072 | reward 45.9\n",
      "it = 4096 | reward 43.9\n",
      "it = 5120 | reward 65.2\n",
      "it = 6144 | reward 62.8\n",
      "it = 7168 | reward 54.6\n",
      "it = 8192 | reward 65.8\n",
      "it = 9216 | reward 24.6\n",
      "it = 10240 | reward 66.5\n",
      "it = 11264 | reward 126.6\n",
      "it = 12288 | reward 110.7\n",
      "it = 13312 | reward 119.9\n",
      "it = 14336 | reward 206.4\n",
      "it = 15360 | reward 72.2\n",
      "it = 16384 | reward 175.4\n",
      "it = 17408 | reward 62.1\n",
      "it = 18432 | reward 44.4\n",
      "it = 19456 | reward 148.9\n",
      "it = 20480 | reward 226.4\n",
      "it = 21504 | reward 147.7\n",
      "it = 22528 | reward 124.7\n",
      "it = 23552 | reward 306.2\n",
      "it = 24576 | reward 368.5\n",
      "it = 25600 | reward 268.6\n",
      "it = 26624 | reward 105.4\n",
      "it = 27648 | reward 110.6\n",
      "it = 28672 | reward 43.2\n",
      "it = 29696 | reward 146.7\n",
      "it = 30720 | reward 346.1\n",
      "it = 31744 | reward 190.0\n",
      "it = 32768 | reward 220.8\n",
      "it = 33792 | reward 280.5\n",
      "it = 34816 | reward 349.4\n",
      "it = 35840 | reward 375.3\n",
      "it = 36864 | reward 342.0\n",
      "it = 37888 | reward 116.9\n",
      "it = 38912 | reward 155.4\n",
      "it = 39936 | reward 330.2\n",
      "it = 40960 | reward 285.6\n",
      "it = 41984 | reward 225.8\n",
      "it = 43008 | reward 242.1\n",
      "it = 44032 | reward 214.2\n",
      "it = 45056 | reward 351.2\n",
      "it = 46080 | reward 268.2\n",
      "it = 47104 | reward 355.8\n",
      "it = 48128 | reward 212.9\n",
      "it = 49152 | reward 166.4\n",
      "it = 50176 | reward 380.1\n",
      "it = 51200 | reward 440.0\n",
      "it = 52224 | reward 437.5\n",
      "it = 53248 | reward 418.1\n",
      "it = 54272 | reward 480.4\n",
      "it = 55296 | reward 142.3\n",
      "it = 56320 | reward 157.1\n",
      "it = 57344 | reward 213.9\n",
      "it = 58368 | reward 262.9\n",
      "it = 59392 | reward 136.5\n",
      "it = 60416 | reward 76.4\n",
      "it = 61440 | reward 157.0\n",
      "it = 62464 | reward 33.8\n",
      "it = 63488 | reward 47.2\n",
      "it = 64512 | reward 38.6\n",
      "it = 65536 | reward 219.1\n",
      "it = 66560 | reward 147.7\n",
      "it = 67584 | reward 167.5\n",
      "it = 68608 | reward 103.1\n",
      "it = 69632 | reward 109.5\n",
      "it = 70656 | reward 49.2\n",
      "it = 71680 | reward 133.5\n",
      "it = 72704 | reward 163.4\n",
      "it = 73728 | reward 334.8\n",
      "it = 74752 | reward 147.5\n",
      "it = 75776 | reward 160.3\n",
      "it = 76800 | reward 104.5\n",
      "it = 77824 | reward 136.5\n",
      "it = 78848 | reward 122.8\n",
      "it = 79872 | reward 122.2\n",
      "it = 80896 | reward 189.7\n",
      "it = 81920 | reward 162.8\n",
      "it = 82944 | reward 131.4\n",
      "it = 83968 | reward 146.0\n",
      "it = 84992 | reward 176.7\n",
      "it = 86016 | reward 246.5\n",
      "it = 87040 | reward 96.0\n",
      "it = 88064 | reward 151.3\n",
      "it = 89088 | reward 23.6\n",
      "it = 90112 | reward 57.0\n",
      "it = 91136 | reward 78.7\n",
      "it = 92160 | reward 77.3\n",
      "it = 93184 | reward 133.6\n",
      "it = 94208 | reward 127.8\n",
      "it = 95232 | reward 118.6\n",
      "it = 96256 | reward 125.4\n",
      "it = 97280 | reward 115.3\n",
      "it = 98304 | reward 104.6\n",
      "it = 99328 | reward 111.8\n",
      "it = 100352 | reward 141.3\n",
      "it = 101376 | reward 150.4\n",
      "======= run = 7 / 18 =========\n",
      "it = 0 | reward 26.8\n",
      "it = 1024 | reward 39.6\n",
      "it = 2048 | reward 44.0\n",
      "it = 3072 | reward 43.1\n",
      "it = 4096 | reward 62.2\n",
      "it = 5120 | reward 69.1\n",
      "it = 6144 | reward 96.5\n",
      "it = 7168 | reward 47.4\n",
      "it = 8192 | reward 80.6\n",
      "it = 9216 | reward 129.3\n",
      "it = 10240 | reward 69.3\n",
      "it = 11264 | reward 52.9\n",
      "it = 12288 | reward 123.8\n",
      "it = 13312 | reward 114.1\n",
      "it = 14336 | reward 75.6\n",
      "it = 15360 | reward 65.8\n",
      "it = 16384 | reward 171.8\n",
      "it = 17408 | reward 178.4\n",
      "it = 18432 | reward 225.2\n",
      "it = 19456 | reward 116.8\n",
      "it = 20480 | reward 255.9\n",
      "it = 21504 | reward 119.4\n",
      "it = 22528 | reward 79.2\n",
      "it = 23552 | reward 116.8\n",
      "it = 24576 | reward 56.8\n",
      "it = 25600 | reward 94.6\n",
      "it = 26624 | reward 231.1\n",
      "it = 27648 | reward 133.9\n",
      "it = 28672 | reward 309.2\n",
      "it = 29696 | reward 226.9\n",
      "it = 30720 | reward 176.7\n",
      "it = 31744 | reward 149.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it = 32768 | reward 186.5\n",
      "it = 33792 | reward 227.0\n",
      "it = 34816 | reward 122.6\n",
      "it = 35840 | reward 176.7\n",
      "it = 36864 | reward 313.8\n",
      "it = 37888 | reward 343.9\n",
      "it = 38912 | reward 295.6\n",
      "it = 39936 | reward 168.1\n",
      "it = 40960 | reward 166.7\n",
      "it = 41984 | reward 47.0\n",
      "it = 43008 | reward 144.9\n",
      "it = 44032 | reward 61.9\n",
      "it = 45056 | reward 189.1\n",
      "it = 46080 | reward 312.0\n",
      "it = 47104 | reward 193.5\n",
      "it = 48128 | reward 264.8\n",
      "it = 49152 | reward 240.8\n",
      "it = 50176 | reward 139.4\n",
      "it = 51200 | reward 141.6\n",
      "it = 52224 | reward 388.9\n",
      "it = 53248 | reward 255.2\n",
      "it = 54272 | reward 169.0\n",
      "it = 55296 | reward 108.5\n",
      "it = 56320 | reward 77.9\n",
      "it = 57344 | reward 139.5\n",
      "it = 58368 | reward 266.8\n",
      "it = 59392 | reward 129.6\n",
      "it = 60416 | reward 229.1\n",
      "it = 61440 | reward 169.2\n",
      "it = 62464 | reward 239.2\n",
      "it = 63488 | reward 164.8\n",
      "it = 64512 | reward 118.6\n",
      "it = 65536 | reward 134.7\n",
      "it = 66560 | reward 206.7\n",
      "it = 67584 | reward 131.3\n",
      "it = 68608 | reward 198.5\n",
      "it = 69632 | reward 115.4\n",
      "it = 70656 | reward 140.6\n",
      "it = 71680 | reward 153.6\n",
      "it = 72704 | reward 97.6\n",
      "it = 73728 | reward 73.7\n",
      "it = 74752 | reward 32.9\n",
      "it = 75776 | reward 21.7\n",
      "it = 76800 | reward 25.2\n",
      "it = 77824 | reward 20.0\n",
      "it = 78848 | reward 18.8\n",
      "it = 79872 | reward 16.3\n",
      "it = 80896 | reward 24.1\n",
      "it = 81920 | reward 57.2\n",
      "it = 82944 | reward 130.4\n",
      "it = 83968 | reward 115.7\n",
      "it = 84992 | reward 110.5\n",
      "it = 86016 | reward 100.5\n",
      "it = 87040 | reward 160.1\n",
      "it = 88064 | reward 170.8\n",
      "it = 89088 | reward 171.8\n",
      "it = 90112 | reward 136.2\n",
      "it = 91136 | reward 165.2\n",
      "it = 92160 | reward 126.6\n",
      "it = 93184 | reward 115.6\n",
      "it = 94208 | reward 256.7\n",
      "it = 95232 | reward 197.9\n",
      "it = 96256 | reward 117.3\n",
      "it = 97280 | reward 105.7\n",
      "it = 98304 | reward 168.5\n",
      "it = 99328 | reward 108.3\n",
      "it = 100352 | reward 151.5\n",
      "it = 101376 | reward 243.3\n",
      "======= run = 8 / 18 =========\n",
      "it = 0 | reward 17.4\n",
      "it = 1024 | reward 41.1\n",
      "it = 2048 | reward 38.1\n",
      "it = 3072 | reward 50.4\n",
      "it = 4096 | reward 62.3\n",
      "it = 5120 | reward 41.9\n",
      "it = 6144 | reward 51.8\n",
      "it = 7168 | reward 52.6\n",
      "it = 8192 | reward 108.6\n",
      "it = 9216 | reward 131.4\n",
      "it = 10240 | reward 57.7\n",
      "it = 11264 | reward 176.6\n",
      "it = 12288 | reward 221.0\n",
      "it = 13312 | reward 133.6\n",
      "it = 14336 | reward 186.3\n",
      "it = 15360 | reward 82.4\n",
      "it = 16384 | reward 78.6\n",
      "it = 17408 | reward 141.8\n",
      "it = 18432 | reward 45.8\n",
      "it = 19456 | reward 253.0\n",
      "it = 20480 | reward 215.0\n",
      "it = 21504 | reward 153.7\n",
      "it = 22528 | reward 175.6\n",
      "it = 23552 | reward 223.6\n",
      "it = 24576 | reward 275.5\n",
      "it = 25600 | reward 290.8\n",
      "it = 26624 | reward 176.1\n",
      "it = 27648 | reward 166.3\n",
      "it = 28672 | reward 175.5\n",
      "it = 29696 | reward 209.2\n",
      "it = 30720 | reward 217.7\n",
      "it = 31744 | reward 142.0\n",
      "it = 32768 | reward 185.0\n",
      "it = 33792 | reward 277.2\n",
      "it = 34816 | reward 283.7\n",
      "it = 35840 | reward 245.9\n",
      "it = 36864 | reward 107.8\n",
      "it = 37888 | reward 131.2\n",
      "it = 38912 | reward 105.5\n",
      "it = 39936 | reward 135.1\n",
      "it = 40960 | reward 125.2\n",
      "it = 41984 | reward 131.2\n",
      "it = 43008 | reward 137.3\n",
      "it = 44032 | reward 154.1\n",
      "it = 45056 | reward 155.9\n",
      "it = 46080 | reward 209.1\n",
      "it = 47104 | reward 133.4\n",
      "it = 48128 | reward 147.4\n",
      "it = 49152 | reward 111.9\n",
      "it = 50176 | reward 57.4\n",
      "it = 51200 | reward 34.9\n",
      "it = 52224 | reward 97.4\n",
      "it = 53248 | reward 88.9\n",
      "it = 54272 | reward 38.5\n",
      "it = 55296 | reward 39.4\n",
      "it = 56320 | reward 48.1\n",
      "it = 57344 | reward 134.9\n",
      "it = 58368 | reward 189.8\n",
      "it = 59392 | reward 101.0\n",
      "it = 60416 | reward 75.4\n",
      "it = 61440 | reward 127.3\n",
      "it = 62464 | reward 140.6\n",
      "it = 63488 | reward 117.6\n",
      "it = 64512 | reward 36.7\n",
      "it = 65536 | reward 56.1\n",
      "it = 66560 | reward 151.5\n",
      "it = 67584 | reward 235.9\n",
      "it = 68608 | reward 143.3\n",
      "it = 69632 | reward 185.1\n",
      "it = 70656 | reward 192.1\n",
      "it = 71680 | reward 98.6\n",
      "it = 72704 | reward 93.7\n",
      "it = 73728 | reward 253.7\n",
      "it = 74752 | reward 170.3\n",
      "it = 75776 | reward 258.0\n",
      "it = 76800 | reward 491.7\n",
      "it = 77824 | reward 239.6\n",
      "it = 78848 | reward 100.2\n",
      "it = 79872 | reward 25.1\n",
      "it = 80896 | reward 16.6\n",
      "it = 81920 | reward 22.1\n",
      "it = 82944 | reward 25.6\n",
      "it = 83968 | reward 109.2\n",
      "it = 84992 | reward 153.9\n",
      "it = 86016 | reward 308.1\n",
      "it = 87040 | reward 500.0\n",
      "it = 88064 | reward 479.9\n",
      "it = 89088 | reward 283.1\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "# Initialisation\n",
    "max_episode = 500\n",
    "def make_env(env_name, max_episode_steps= 500):\n",
    "    return TimeLimit(gymnasium.make('CartpoleEnvCacla'), max_episode_steps)\n",
    "\n",
    "env_name = 'CartpoleEnvCacla'\n",
    "train_env = make_env(env_name, max_episode_steps=max_episode)\n",
    "eval_env = make_env(env_name max_episode_steps=max_episode)\n",
    "\n",
    "all_perfs = []\n",
    "n_runs = 18\n",
    "discount_factor = 0.9\n",
    "noise_std= 0.3\n",
    "exploration = 'gaussian'\n",
    "path = f'log/{exploration}/now_gamma{int(discount_factor*100)}_std{noise_std}'\n",
    "\n",
    "if not os.path.exists(path): \n",
    "    print()\n",
    "    os.mkdir(path)\n",
    "\n",
    "for run in range(1,n_runs+1):\n",
    "    print(f'======= {run = } / {n_runs} =========')\n",
    "    cacla = Cacla(in_dim=4, h_dim=12, \n",
    "                  discount_factor=discount_factor, \n",
    "                  gaussian_noise=0.1,\n",
    "                 var=True,\n",
    "                 exploration=exploration)\n",
    "    optim_crit = SGD(cacla.critic.parameters(), lr=0.01)\n",
    "    optim_act = SGD(cacla.actor.parameters(), lr=0.01)\n",
    "    optim = (optim_crit, optim_act)\n",
    "    scores = train(eval_env, train_env, cacla, optim, \n",
    "                   eval_interval=1024, \n",
    "                   step_max=102400,\n",
    "                  n_test=10,\n",
    "                  noise_std= noise_std)\n",
    "    scores = np.array(scores)\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    np.savetxt(path+f'/{timestr}.log', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_env = wrap_env(TimeLimit(ContinuousEnvCACLA(render_mode='rgb_array'),max_episode_steps=500))\n",
    "observation, _ = rec_env.reset()\n",
    "maxEvaluations = 2\n",
    "evaluation = 0\n",
    "score = []\n",
    "total = 0\n",
    "while evaluation < maxEvaluations:\n",
    "    rec_env.render()\n",
    "    _, a0 = cacla(observation)  \n",
    "    action = a0\n",
    "    observation, reward, done, truncated, _ = rec_env.step(action) \n",
    "    total += reward\n",
    "    if done or truncated:\n",
    "      score.append(total)\n",
    "      total = 0\n",
    "      evaluation = evaluation + 1\n",
    "      observation, _ = rec_env.reset()\n",
    "rec_env.close()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(path):\n",
    "    X = []\n",
    "    for data_file in os.listdir(path):\n",
    "        filepath = path + data_file \n",
    "        X.append(np.loadtxt(filepath)[:,:1227])\n",
    "    return np.array(X)\n",
    "path = 'log/gaussian/gamma90/'\n",
    "X = get(path)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X:\n",
    "    plt.plot(x[:,0], x[:,1], alpha=0.1)\n",
    "plt.xlabel('training iterations')\n",
    "plt.ylabel('performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.mean(0)\n",
    "plt.plot(x[:,0], x[:,1])\n",
    "plt.xlabel('training iterations')\n",
    "plt.ylabel('performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
